# Отток клиентов

# Цель и основные шаги работы

**Цель работы**: Необходимо построить модель с предельно большим значением F1-меры (> 0.59), чтобы прогнозировать, уйдёт клиент из банка в ближайшее время или нет. 

**Основные шаги работы**:
1. Загрузить и подготовить данные.
1. Исследовать баланс классов, обучить модель без учёта дисбаланса.
1. Улучшить качество модели, учитывая дисбаланс классов. Обучить разные модели и найти лучшую.
1. Провести финальное тестирование.

# Описание данных
**Признаки**
 * индекс строки в данных
 * уникальный идентификатор клиента
 * фамилия
 * кредитный рейтинг
 * страна проживания
 * пол
 * возраст
 * количество недвижимости у клиента
 * баланс на счёте
 * количество продуктов банка, используемых клиентом
 * наличие кредитной карты
 * активность клиента
 * предполагаемая зарплата  


**Целевой признак**
 * факт ухода клиента
 
## Использумый стек
Python, pandas, matplotlib, sklearn

## Вывод
В результате проведанной рабоыт получили следующие результаты.

Построили модели ***без учета дисбаланса классов***:
* Решающее дерево (decision tree);
* Случайный лес (random forest); 
* Логистическая регрессия (logistic regression).

И посчитали основные метрики:
* Accuracy;
* Recall;
* Precission; 
* F1;
* AUC-ROC.

Получили следующие результаты.  

* ***DecisionTreeClassifier***

**Метрики**  | **Default** |
:-------------: | :-------------: |
Accuracy	 | 0.794500 |
Recall | 0.497608 |
Precission | 0.508557 |
F1 | 0.503023 |
AUC-ROC | 0.685277 |

* ***LogisticRegression***

**Метрики**  | **Default** |
:-------------: | :-------------: |
Accuracy	 | 0.802000 |
Recall | 0.234450 |
Precission | 0.563218 |
F1 | 0.331081 |
AUC-ROC | 0.758750 |

* ***RandomForestClassifier***

**Метрики**  | **Default** |
:-------------: | :-------------: |
Accuracy	 | 0.857500 |
Recall | 0.459330 |
Precission | 0.764940 |
F1 | 0.573991 |
AUC-ROC | 0.839989 |


Лучшее значение **F1  = 0.574** выдает **RandomForestClassifier**.  


Проверили качество моделей ***с учетом дисбаланс классов***. Использовали следующие подходы:  
* Взвешивание классов;
* Увеличение выборки;
* Уменьшение выборки.

Получили следующие результаты:


* ***DecisionTreeClassifier***

**Метрики**  | **Default** | **Взвешивание классов** |	**Увеличение выборки** | **Уменьшение выборки** |
:-------------: | :-------------: | :-------------: | :-------------: | :-------------: |
Accuracy|	0.79|	0.79|	0.79|	0.52|
Recall|	    0.50|	0.48|	0.49|	0.55|
Precission|	0.51|	0.49|	0.50|	0.23|
F1|	        0.50|	0.49|	0.49|	0.32|
AUC-ROC|	0.69|	0.68|	0.68|	0.53|

* ***LogisticRegression***

**Метрики**  | **Default** | **Взвешивание классов** |	**Увеличение выборки** | **Уменьшение выборки** |
:-------------: | :-------------: | :-------------: | :-------------: | :-------------: |
Accuracy|	0.80|	0.70|	0.70|	0.46|
Recall|	    0.23|	0.68|	0.68|	0.46|
Precission|	0.56|	0.38|	0.38|	0.18|
F1|	        0.33|	0.49|	0.49|	0.26|
AUC-ROC|	0.76|	0.76|	0.76|	0.4|

* ***RandomForestClassifier***

**Метрики**  | **Default** | **Взвешивание классов** |	**Увеличение выборки** | **Уменьшение выборки** |
:-------------: | :-------------: | :-------------: | :-------------: | :-------------: |
Accuracy|	0.86|	0.86|	0.85|	0.51|
Recall|	    0.46|	0.44|	0.55|	0.51|
Precission|	0.76|	0.78|	0.67|	0.21|
F1|	        0.57|	0.56|	0.61|	0.30|
AUC-ROC|	0.84|	0.84|	0.84|	0.52|


Лучшей моделью оказалась **RandomForestClassifier**, используя метод увеличения выборки, со значением **F1 = 0.61** и **AUC_ROC = 0.84**.  
С помощью `GridSearchCV` подобрали лучшие значения гиперпараметров для **RandomForestClassifier**: 
* max_depth = 11;
* n_estimators = 100.

На **валидационной выборке** получили следующие значения метрик:

**Метрики**  | **Значения** |
:-------------: | :-------------: |
Accuracy	 | 0.83 |
Recall | 0.65 |
Precission | 0.59 |
F1 | 0.62 |
AUC-ROC | 0.85 |

На **тестовой выборке** и получили следующие значения метрик:

**Метрики**  | **Значения** |
:-------------: | :-------------: |
Accuracy	 | 0.83 |
Recall | 0.64 |
Precission | 0.58 |
F1 | 0.61 |
AUC-ROC | 0.86 |

В результате значение F1 = 0.61 (по условию задачи необходимо было > 0.59) и значение AUC-ROC = 0.86.